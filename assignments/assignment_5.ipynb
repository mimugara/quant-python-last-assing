{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5\n",
    "\n",
    "Deadline: 11.06.2025 12:00 CEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "Develop an investment strategy for the Swiss equity market, backtest it using the provided datasets (`market_data.parquet`, `jkp_data.parquet`, `spi_index.csv`) and analyze its performance by benchmarking it against the SPI index. Work with the existing code infrastructure (`qpmwp-course`) and extend it by implementing any additional components needed for the strategy. Write a report that presents your methodology and the results.\n",
    "\n",
    "### Coding (15 points)\n",
    "\n",
    "- Selection:\n",
    "  Implement selection item builder functions (via `SelectionItemBuilder`) to filter stocks based on specific criteria (e.g., exclude low-quality or high-volatility stocks).\n",
    "\n",
    "- Optimization Data & Constraints:\n",
    "  Implement functions to prepare optimization data (via `OptimizationItemBuilder`), including any econometric or machine learning-based predictions. These functions should also define optimization constraints (e.g., stock, sector, or factor exposure limits).\n",
    "\n",
    "- Optimization Model:\n",
    "  If you choose to create a custom optimization model, develop a class inheriting from Optimization (similar to `MeanVariance`, `LeastSquares`, or `BlackLitterman`). Your class should include methods set_objective and solve for defining the objective function and solving the optimization problem.\n",
    "\n",
    "- Machine Learning Prediction:\n",
    "  Integrate a machine learning model to estimate inputs for the optimization, such as expected returns or risk. This could include regression, classification, or learning-to-rank models. I suggest you to use the provided jkp_data as features, but you may also create your own (e.g., technical indicators computed on the return or price series).\n",
    "\n",
    "- Simulation:\n",
    "  Backtest the strategy and simulate portfolio returns. Account for fixed costs (1% per annum) and variable (transaction) costs (0.2% per rebalancing).\n",
    "\n",
    "\n",
    "### Report (15 points):\n",
    "\n",
    "Generate an HTML report with the following sections:\n",
    "\n",
    "- High-level strategy overview: Describe the investment strategy you developed.\n",
    "\n",
    "- Detailed explanation of the backtesting steps: Offer a more comprehensive breakdown of the backtesting process, including a description of the models implemented (e.g., details of the machine learning method used).\n",
    "\n",
    "- Backtesting results:\n",
    "    \n",
    "    - Charts: Include visual representations (e.g., cumulative performance charts, rolling 3-year returns, etc.).\n",
    "    - Descriptive statistics: Present key statistics such as mean, standard deviation, drawdown, turnover, and Sharpe ratio (or any other relevant metric) for the full backtest period as well as for subperiods (e.g., the last 5 years, or during bull vs. bear market phases).\n",
    "    - Compare your strategy against the SPI index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# LSTM Mean–Variance Portfolio  ·  50 JKP factors \n",
    "\n",
    "#  deterministic μ (no MC-Dropout)\n",
    "#  α-boost 1.8  +  turnover shrink 1.00 / 0.95\n",
    "#  fixed λ = 1.5   (no dynamic rescale)\n",
    "\n",
    "import os, sys, random, logging, warnings, types, itertools\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helper_functions import load_data_spi\n",
    "from estimation.covariance import Covariance\n",
    "from optimization.optimization import MeanVariance, Objective\n",
    "from backtesting.backtest_data import BacktestData\n",
    "from backtesting.backtest_service import BacktestService\n",
    "from backtesting.backtest import Backtest\n",
    "from backtesting.backtest_item_builder_classes import SelectionItemBuilder, OptimizationItemBuilder\n",
    "from backtesting.backtest_item_builder_functions import (\n",
    "    bibfn_selection_min_volume, bibfn_selection_gaps, bibfn_return_series,\n",
    "    bibfn_budget_constraint, bibfn_box_constraints)\n",
    "from qpsolvers import available_solvers\n",
    "\n",
    "#  reproducibility and logging \n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    \n",
    "                    format=\"%(asctime)s %(levelname)s: %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "sys.modules[\"xgboost\"] = types.ModuleType(\"xgboost\")   # qpsolvers workaround\n",
    "\n",
    "# paths/dates\n",
    "\n",
    "DATA_PATH  = r\"C:\\Valentino\\UZH\\Quant portfolio management with Python\\quant-python-last-assing\\data\"\n",
    "START_DATE = \"2016-01-01\"\n",
    "REB_PERIOD = 84 # quarterly\n",
    "TRADING_DAYS = 252\n",
    "\n",
    "# model and optimiser knobs\n",
    "INIT_LAMBDA = 1.5\n",
    "ALPHA_BOOST   = 1.80\n",
    "GAMMA         = 0.002\n",
    "\n",
    "HIDDEN, DROPOUT = 128, 0.30\n",
    "MAX_EPOCHS, PATIENCE = 100, 10\n",
    "LR, WD  = 1e-3, 1e-4\n",
    "SEQ_LEN = 30   # look-back 30 days\n",
    "FCAST_HORIZON = 1\n",
    "\n",
    "TURN_SHRINK_LOW, TURN_SHRINK_HIGH = 1.00, 0.95\n",
    "DISP_TH = 0.05\n",
    "\n",
    "FIXED_ANNUAL, VC = 0.01, 0.002\n",
    "FC = FIXED_ANNUAL * (REB_PERIOD / TRADING_DAYS)\n",
    "\n",
    "\n",
    "#  50 JKP factors \n",
    "FUND_COLS = [\n",
    "    \n",
    "    \"be_me\", \"op_at\", \"inv_gr1a\", \"ret_12_1\", \"beta_60m\",\n",
    "    \n",
    "    \"gp_at\", \"at_me\", \"rd_sale\", \"turnover_126d\", \"ivol_capm_252d\", \"f_score\",\n",
    "    \n",
    "    \"niq_be\", \"cash_at\", \"sale_gr1\", \"sale_gr3\", \"sale_me\", \"ocf_me\",\n",
    "    \"netdebt_me\", \"gp_atl1\", \"op_atl1\", \"oaccruals_at\", \"taccruals_at\",\n",
    "    \"capx_gr1\", \"capx_gr2\", \"capx_gr3\", \"inv_gr1\", \"rd_me\", \"rd5_at\",\n",
    "    \"age\", \"tangibility\", \"kz_index\", \"ivol_ff3_21d\", \"ivol_hxz4_21d\",\n",
    "    \"rvol_21d\", \"betadown_252d\", \"bidaskhl_21d\", \"rmax1_21d\",\n",
    "    \"iskew_capm_21d\", \"coskew_21d\", \"turnover_var_126d\", \"dolvol_126d\",\n",
    "    \"ami_126d\", \"zero_trades_252d\", \"corr_1260d\", \"rmax5_21d\", \"ret_6_1\",\n",
    "    \"ret_9_1\", \"ret_12_7\", \"mispricing_mgmt\", \"qmj_growth\"\n",
    "]  \n",
    "\n",
    "technical_features: pd.DataFrame = pd.DataFrame()\n",
    "\n",
    "# helper to build tech panel \n",
    "def create_tech(ret: pd.DataFrame, vol: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    f, cum = pd.DataFrame(index=ret.index), (1+ret.fillna(0)).cumprod()\n",
    "    for m in [1,3,6,12]:\n",
    "        d=m*21; f[f\"mom_{m}m\"]=(cum/cum.shift(d)-1).mean(axis=1)\n",
    "\n",
    "    for m in [1,3,6]:\n",
    "        d=m*21; f[f\"vol_{m}m\"]=(ret.rolling(d,int(.7*d)).std().mean(axis=1)*np.sqrt(252))\n",
    "\n",
    "    f[\"vol_trend\"] = (vol.rolling(21,15).mean()/vol.rolling(63,45).mean()-1).mean(axis=1)\n",
    "    f[\"breadth\"]    = (ret>0).mean(axis=1)\n",
    "    f[\"dispersion\"] = ret.std(axis=1)\n",
    "\n",
    "    return f.fillna(0)\n",
    "\n",
    "class LSTMReturnPredictor(nn.Module):\n",
    "\n",
    "    def __init__(self, inp:int, n:int):\n",
    "        super().__init__()\n",
    "        self.lstm=nn.LSTM(inp,HIDDEN,2,dropout=DROPOUT,batch_first=True)\n",
    "        self.dp=nn.Dropout(DROPOUT); self.fc=nn.Linear(HIDDEN,n)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out,_=self.lstm(x)\n",
    "        return torch.tanh(self.fc(self.dp(out[:,-1,:])))*0.02\n",
    "\n",
    "def pick_solver(pref=\"osqp\"):\n",
    "    solvers=available_solvers() if callable(available_solvers) else available_solvers\n",
    "    return pref if pref in solvers else (solvers[0] if solvers else pref)\n",
    "\n",
    "# optimisation class\n",
    "class LSTMOptimization(MeanVariance):\n",
    "\n",
    "    def __init__(self, **kw):\n",
    "        super().__init__(solver_name=pick_solver(), **kw)\n",
    "        self.net:Optional[LSTMReturnPredictor]=None\n",
    "        self.input_dim:Optional[int]=None\n",
    "        self.data:Optional[BacktestData]=None\n",
    "\n",
    "    def _train(self,net,x,y):\n",
    "        dev=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        net.to(dev); x,y=x.to(dev),y.to(dev)\n",
    "        opt=torch.optim.AdamW(net.parameters(),lr=LR,weight_decay=WD)\n",
    "        crit=nn.MSELoss(); best=np.inf; pat=0\n",
    "\n",
    "        for epoch in range(MAX_EPOCHS):\n",
    "            opt.zero_grad(); loss=crit(net(x),y); loss.backward(); opt.step()\n",
    "\n",
    "            if loss.item()+1e-8<best: best,pat=loss.item(),0\n",
    "            else:\n",
    "                pat+=1\n",
    "                if pat>=PATIENCE: break\n",
    "        net.cpu()\n",
    "\n",
    "    def _flat_funda(self,date,ids):\n",
    "        jkp=self.data.jkp_data\n",
    "\n",
    "        if jkp is None: return None\n",
    "        dates=jkp.index.get_level_values(0).unique()\n",
    "        idx=dates.searchsorted(date,side=\"right\")-1\n",
    "\n",
    "        if idx<0: return None\n",
    "        eff=dates[idx]\n",
    "        try: mat=jkp[FUND_COLS].xs(eff,level=0).loc[ids].fillna(0)\n",
    "        except KeyError: return None\n",
    "        mat=(mat-mat.mean())/mat.std().replace(0,1)\n",
    "        logger.info(\"Fundamentals %s → %s | k=%d\",eff.date(),date.date(),len(mat.columns))\n",
    "\n",
    "        return mat.to_numpy().ravel()\n",
    "    \n",
    "    def set_objective(self,optimization_data):\n",
    "\n",
    "        X=optimization_data[\"return_series\"]; ids=X.columns.tolist()\n",
    "        cov=self.covariance.estimate(X=X,inplace=False).fillna(0)\n",
    "        tech=technical_features.reindex(X.index).fillna(0)\n",
    "        reb=X.index[-1]; funda=self._flat_funda(reb,ids)\n",
    "\n",
    "        seqs,tgt=[],[]\n",
    "\n",
    "        for i in range(SEQ_LEN,len(X)-FCAST_HORIZON):\n",
    "            blk=np.hstack([X.values[i-SEQ_LEN:i],tech.values[i-SEQ_LEN:i]])\n",
    "            if funda is not None:\n",
    "                blk=np.hstack([blk,np.repeat(funda[np.newaxis,:],SEQ_LEN,0)])\n",
    "            seqs.append(blk); tgt.append(X.values[i+FCAST_HORIZON])\n",
    "        mu=pd.Series(0.,index=ids)\n",
    "\n",
    "        if len(seqs)>=50:\n",
    "            x_t=torch.tensor(np.stack(seqs),dtype=torch.float32)\n",
    "            y_t=torch.tensor(np.stack(tgt ),dtype=torch.float32)\n",
    "            d=x_t.shape[-1]\n",
    "            if (self.net is None) or (d!=self.input_dim):\n",
    "                self.input_dim=d; self.net=LSTMReturnPredictor(d,len(ids))\n",
    "            self._train(self.net,x_t,y_t)\n",
    "            with torch.no_grad():\n",
    "                mu_hat=self.net(torch.tensor(seqs[-1:],dtype=torch.float32)).cpu().numpy().flatten()\n",
    "            mu=pd.Series(mu_hat,index=ids).clip(-0.05,0.05)\n",
    "\n",
    "        sig=pd.Series(np.sqrt(np.diag(cov)),index=ids)\n",
    "        mu=(mu/sig.pow(0.5)*ALPHA_BOOST).fillna(0)\n",
    "        disp=technical_features.loc[reb,\"dispersion\"]\n",
    "        mu*=TURN_SHRINK_LOW if disp<DISP_TH else TURN_SHRINK_HIGH\n",
    "\n",
    "        lam=INIT_LAMBDA  \n",
    "        P=cov.values*2*lam + np.eye(len(ids))*2*GAMMA\n",
    "        self.objective=Objective(q=-mu,\n",
    "                                 P=pd.DataFrame(P,index=ids,columns=ids))\n",
    "\n",
    "# performance helper\n",
    "def perf(ret,bench):\n",
    "    df=pd.concat([ret.rename(\"LSTM\"),bench.rename(\"SPI\")],axis=1).dropna()\n",
    "    cum=(1+df).cumprod(); out={}\n",
    "    for c in df:\n",
    "        r=df[c]; ar, av=r.mean()*252, r.std()*np.sqrt(252)\n",
    "        dd=(cum[c]-cum[c].cummax())/cum[c].cummax()\n",
    "        out[c]=[ar,av,ar/av if av>0 else np.nan,dd.min()]\n",
    "    return pd.DataFrame(out,index=[\"AnnRet\",\"AnnVol\",\"Sharpe\",\"MaxDD\"]).T,cum\n",
    "\n",
    "# back-test runner \n",
    "def run_backtest(plot=True):\n",
    "    global technical_features\n",
    "    data=BacktestData()\n",
    "    data.market_data=pd.read_parquet(os.path.join(DATA_PATH,\"market_data.parquet\"))\n",
    "    try: data.jkp_data=pd.read_parquet(os.path.join(DATA_PATH,\"jkp_data.parquet\"))\n",
    "    except FileNotFoundError: data.jkp_data=None\n",
    "    data.bm_series=load_data_spi(path=DATA_PATH)\n",
    "    technical_features=create_tech(data.get_return_series(),\n",
    "                                   data.get_volume_series())\n",
    "\n",
    "    dates=data.market_data.index.get_level_values(\"date\").unique().sort_values()\n",
    "    rdates=dates[dates>=pd.to_datetime(START_DATE)][::REB_PERIOD]\n",
    "\n",
    "    sel={\"vol\":SelectionItemBuilder(bibfn=bibfn_selection_min_volume,width=252,\n",
    "                                    min_volume=500_000,agg_fn=np.median),\n",
    "         \"gaps\":SelectionItemBuilder(bibfn=bibfn_selection_gaps,width=252,n_days=7)}\n",
    "    opt={\"ret\":OptimizationItemBuilder(bibfn=bibfn_return_series,width=252,fill_value=0),\n",
    "         \"budget\":OptimizationItemBuilder(bibfn=bibfn_budget_constraint,budget=1.0),\n",
    "         \"box\":OptimizationItemBuilder(bibfn=bibfn_box_constraints,lower=0,upper=0.20)}\n",
    "\n",
    "    optimization=LSTMOptimization()\n",
    "    optimization.data=data\n",
    "    bs=BacktestService(data=data,\n",
    "                       selection_item_builders=sel,\n",
    "                       optimization_item_builders=opt,\n",
    "                       optimization=optimization,\n",
    "                       rebdates=[d.strftime(\"%Y-%m-%d\") for d in rdates])\n",
    "    bt=Backtest(); bt.run(bs)\n",
    "\n",
    "    sim=bt.strategy.simulate(return_series=data.get_return_series(),fc=FC,vc=VC)\n",
    "    metrics,cum=perf(sim,data.bm_series)\n",
    "    if plot:\n",
    "        print(\"\\nPerformance metrics\\n\"); print(metrics.round(4))\n",
    "        cum.plot(figsize=(12,6),title=\"Cumulative return – LSTM vs SPI\")\n",
    "        plt.ylabel(\"Cumulative return\"); plt.tight_layout(); plt.show()\n",
    "    return metrics,cum\n",
    "\n",
    "# CLI \n",
    "if __name__==\"__main__\":\n",
    "    run_backtest(plot=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
